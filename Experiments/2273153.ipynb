{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# [AI训练营]paddleclas实现图像分类baseline大作业\n",
    "\n",
    "多彩缤纷的世界，相信大家的相册里都有着许许多多的美景，这次我们要做的是对美景图片进行场景分类。\n",
    "\n",
    "# 一、项目背景\n",
    "\n",
    "由于我本人比较喜欢拍摄风景图片，但懒于分类，便想到运用paddleclas进行场景分类，来解决这一问题。\n",
    "\n",
    "\n",
    "\n",
    "# 二、数据集简介\n",
    "\n",
    "\n",
    "项目使用了paddle的场景5分类数据集，一共有3499条数据，都是风景图片。\n",
    "## 数据集介绍\n",
    "\n",
    "<font size=\"3px\" color=\"red\">本次大数据集有五个可供大家选择。分别是：</font>   \n",
    "1. 猫12分类\n",
    "2. 垃圾40分类\n",
    "\n",
    "<font size=\"3px\" color=\"red\"> 3. 场景5分类</font> \n",
    "\n",
    "\n",
    "4. 食物5分类\n",
    "5. 蝴蝶20分类\n",
    "\n",
    "\n",
    "**我要做的是场景分类，所以选择的data是“场景5分类”**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 先导入库\r\n",
    "from sklearn.utils import shuffle\r\n",
    "import os\r\n",
    "import pandas as pd\r\n",
    "import numpy as np\r\n",
    "from PIL import Image\r\n",
    "import paddle\r\n",
    "import paddle.nn as nn\r\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 忽略（垃圾）警告信息\r\n",
    "# 在python中运行代码经常会遇到的情况是——代码可以正常运行但是会提示警告，有时特别讨厌。\r\n",
    "# 那么如何来控制警告输出呢？其实很简单，python通过调用warnings模块中定义的warn()函数来发出警告。我们可以通过警告过滤器进行控制是否发出警告消息。\r\n",
    "import warnings\r\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 2.1 解压数据集，查看数据的结构"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 项目挂载的数据集先解压出来，待解压完毕，刷新后可发现左侧文件夹根目录出现五个zip\r\n",
    "!unzip -oq /home/aistudio/data/data103736/五种图像分类数据集.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "左侧可以看到如图所示五个zip    \n",
    "![](https://ai-studio-static-online.cdn.bcebos.com/f8bc5b21a0ba49b4b78b6e7b18ac0341dfb14cf545b14c83b1f597b6ee8109bb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 本次项目选择场景5分类作为数据集\r\n",
    "# (此处需要你根据自己的选择进行解压对应的文件)\r\n",
    "# 解压完毕左侧出现文件夹，即为需要分类的文件\r\n",
    "!unzip -oq /home/aistudio/场景5分类.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 directories, 3498 files\r"
     ]
    }
   ],
   "source": [
    "# 查看结构，正为一个类别下有一系列对应的图片\r\n",
    "!tree scenes/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "**五类场景图片**  \n",
    "1. river\n",
    "2. lawn\n",
    "3. church\n",
    "4. ice\n",
    "5. desert    \n",
    "\n",
    "具体结构如下：\n",
    "```\n",
    "scenes/\n",
    "├── river\n",
    "│   ├── 1005649.jpg\n",
    "│   ├── 1011328.jpg\n",
    "│   ├── 101251.jpg\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 2.2 拿到总的训练数据txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "数据集大小： 3499\n"
     ]
    }
   ],
   "source": [
    "import os\r\n",
    "# -*- coding: utf-8 -*-\r\n",
    "# 根据官方paddleclas的提示，我们需要把图像变为两个txt文件\r\n",
    "# train_list.txt（训练集）\r\n",
    "# val_list.txt（验证集）\r\n",
    "# 先把路径搞定 比如：foods/beef_carpaccio/855780.jpg ,读取到并写入txt \r\n",
    "\r\n",
    "# 根据左侧生成的文件夹名字来写根目录\r\n",
    "dirpath = \"scenes\"\r\n",
    "# 先得到总的txt后续再进行划分，因为要划分出验证集，所以要先打乱，因为原本是有序的\r\n",
    "def get_all_txt():\r\n",
    "    all_list = []\r\n",
    "    i = 0 # 标记总文件数量\r\n",
    "    j = 0 # 标记文件类别\r\n",
    "    for root,dirs,files in os.walk(dirpath): # 分别代表根目录、文件夹、文件\r\n",
    "        for file in files:\r\n",
    "            i = i + 1 \r\n",
    "            # 文件中每行格式： 图像相对路径      图像的label_id（数字类别）（注意：中间有空格）。              \r\n",
    "            imgpath = os.path.join(root,file)\r\n",
    "            all_list.append(imgpath+\" \"+str(j)+\"\\n\")\r\n",
    "\r\n",
    "        j = j + 1\r\n",
    "\r\n",
    "    allstr = ''.join(all_list)\r\n",
    "    f = open('all_list.txt','w',encoding='utf-8')\r\n",
    "    f.write(allstr)\r\n",
    "    return all_list , i\r\n",
    "all_list,all_lenth = get_all_txt()\r\n",
    "print(\"数据集大小：\",all_lenth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 2.3 数据打乱"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "打乱成功，并重新写入文本\n"
     ]
    }
   ],
   "source": [
    "# 把数据打乱\r\n",
    "all_list = shuffle(all_list)\r\n",
    "allstr = ''.join(all_list)\r\n",
    "f = open('all_list.txt','w',encoding='utf-8')\r\n",
    "f.write(allstr)\r\n",
    "print(\"打乱成功，并重新写入文本\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 2.4 数据划分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3149\n",
      "350\n"
     ]
    }
   ],
   "source": [
    "# 按照比例划分数据集 食品的数据有3499张图片，不算大数据，一般9:1即可\r\n",
    "train_size = int(all_lenth * 0.9)\r\n",
    "train_list = all_list[:train_size]\r\n",
    "val_list = all_list[train_size:]\r\n",
    "\r\n",
    "print(len(train_list))\r\n",
    "print(len(val_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_list.txt 生成成功！\n",
      "val_list.txt 生成成功！\n"
     ]
    }
   ],
   "source": [
    "# 运行cell，生成训练集txt \r\n",
    "train_txt = ''.join(train_list)\r\n",
    "f_train = open('train_list.txt','w',encoding='utf-8')\r\n",
    "f_train.write(train_txt)\r\n",
    "f_train.close()\r\n",
    "print(\"train_list.txt 生成成功！\")\r\n",
    "\r\n",
    "# 运行cell，生成验证集txt\r\n",
    "val_txt = ''.join(val_list)\r\n",
    "f_val = open('val_list.txt','w',encoding='utf-8')\r\n",
    "f_val.write(val_txt)\r\n",
    "f_val.close()\r\n",
    "print(\"val_list.txt 生成成功！\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 3 安装paddleclas\n",
    "\n",
    "数据集核实完搞定成功的前提下，可以准备更改原文档的参数进行实现自己的图片分类了！\n",
    "\n",
    "这里采用paddleclas的2.2版本，好用！"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fatal: destination path 'PaddleClas' already exists and is not an empty directory.\r\n"
     ]
    }
   ],
   "source": [
    "# 先把paddleclas安装上再说\r\n",
    "# 安装paddleclas以及相关三方包(好像studio自带的已经够用了，无需安装了)\r\n",
    "!git clone https://gitee.com/paddlepaddle/PaddleClas.git -b release/2.2\r\n",
    "# 我这里安装相关包时，花了30几分钟还有错误提示，不管他即可\r\n",
    "#!pip install --upgrade -r PaddleClas/requirements.txt -i https://mirror.baidu.com/pypi/simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/aistudio/PaddleClas\n",
      "dataset  hubconf.py   MANIFEST.in    README_ch.md  requirements.txt\r\n",
      "deploy\t __init__.py  paddleclas.py  README_en.md  setup.py\r\n",
      "docs\t LICENSE      ppcls\t     README.md\t   tools\r\n"
     ]
    }
   ],
   "source": [
    "#因为后续paddleclas的命令需要在PaddleClas目录下，所以进入PaddleClas根目录，执行此命令\r\n",
    "%cd PaddleClas\r\n",
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 将图片移动到paddleclas下面的数据集里面\r\n",
    "# 至于为什么现在移动，也是我的一点小技巧，防止之前移动的话，生成的txt的路径是全路径，反而需要去掉路径的一部分\r\n",
    "!mv ../scenes/ dataset/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 挪动文件到对应目录\r\n",
    "!mv ../all_list.txt dataset/scenes\r\n",
    "!mv ../train_list.txt dataset/scenes\r\n",
    "!mv ../val_list.txt dataset/scenes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 3.1 修改配置文件\n",
    "#### 3.1.1\n",
    "主要是以下几点：分类数、图片总量、训练和验证的路径、图像尺寸、数据预处理、训练和预测的num_workers: 0\n",
    "```\n",
    "分类数：6类（包含0类）\n",
    "图片总量：3499\n",
    "训练路径：./dataset/scenes/train_list.txt\n",
    "验证路径：./dataset/scenes/val_list.txt\n",
    "图像尺寸：[3, 224, 224] \n",
    "```\n",
    "路径如下：\n",
    ">PaddleClas/ppcls/configs/quick_start/new_user/ShuffleNetV2_x0_25.yaml\n",
    "\n",
    "<font size=\"3px\" color=\"red\">（主要的参数已经进行注释，一定要过一遍）</font>\n",
    "```\n",
    "调参修改的参数：\n",
    "训练轮次epochs: 40 \n",
    "使用网络name: ResNet50_vc\n",
    "学习率learning_rate: 0.0125\n",
    "相关路径path: ./dataset/scenes\n",
    "```\n",
    "```\n",
    "# global configs\n",
    "Global:\n",
    "  checkpoints: null\n",
    "  pretrained_model: null\n",
    "  output_dir: ./output/\n",
    "  # 使用GPU训练\n",
    "  device: gpu\n",
    "  # 每几个轮次保存一次\n",
    "  save_interval: 1 \n",
    "  eval_during_train: True\n",
    "  # 每几个轮次验证一次\n",
    "  eval_interval: 1 \n",
    "  # 训练轮次\n",
    "  epochs: 40 \n",
    "  print_batch_step: 1\n",
    "  use_visualdl: True #开启可视化（目前平台不可用）\n",
    "  # used for static mode and model export\n",
    "  # 图像大小\n",
    "  image_shape: [3, 224, 224] \n",
    "  save_inference_dir: ./inference\n",
    "  # training model under @to_static\n",
    "  to_static: False\n",
    "\n",
    "# model architecture\n",
    "Arch:\n",
    "  # 采用的网络\n",
    "  name: ResNet50_vc\n",
    "  # 类别数 多了个0类 0-5 (0无用) \n",
    "  class_num: 6 \n",
    " \n",
    "# loss function config for traing/eval process\n",
    "Loss:\n",
    "  Train:\n",
    "\n",
    "    - CELoss: \n",
    "        weight: 1.0\n",
    "  Eval:\n",
    "    - CELoss:\n",
    "        weight: 1.0\n",
    "\n",
    "\n",
    "Optimizer:\n",
    "  name: Momentum\n",
    "  momentum: 0.9\n",
    "  lr:\n",
    "    name: Piecewise\n",
    "    learning_rate: 0.0125\n",
    "    decay_epochs: [30, 60, 90]\n",
    "    values: [0.1, 0.01, 0.001, 0.0001]\n",
    "  regularizer:\n",
    "    name: 'L2'\n",
    "    coeff: 0.0005\n",
    "\n",
    "\n",
    "# data loader for train and eval\n",
    "DataLoader:\n",
    "  Train:\n",
    "    dataset:\n",
    "      name: ImageNetDataset\n",
    "      # 根路径\n",
    "      image_root: ./dataset/\n",
    "      # 前面自己生产得到的训练集文本路径\n",
    "      cls_label_path: ./dataset/scenes/train_list.txt\n",
    "      # 数据预处理\n",
    "      transform_ops:\n",
    "        - DecodeImage:\n",
    "            to_rgb: True\n",
    "            channel_first: False\n",
    "        - ResizeImage:\n",
    "            resize_short: 256\n",
    "        - CropImage:\n",
    "            size: 224\n",
    "        - RandFlipImage:\n",
    "            flip_code: 1\n",
    "        - NormalizeImage:\n",
    "            scale: 1.0/255.0\n",
    "            mean: [0.485, 0.456, 0.406]\n",
    "            std: [0.229, 0.224, 0.225]\n",
    "            order: ''\n",
    "\n",
    "    sampler:\n",
    "      name: DistributedBatchSampler\n",
    "      batch_size: 128\n",
    "      drop_last: False\n",
    "      shuffle: True\n",
    "    loader:\n",
    "      num_workers: 0\n",
    "      use_shared_memory: True\n",
    "\n",
    "  Eval:\n",
    "    dataset: \n",
    "      name: ImageNetDataset\n",
    "      # 根路径\n",
    "      image_root: ./dataset/\n",
    "      # 前面自己生产得到的验证集文本路径\n",
    "      cls_label_path: ./dataset/scenes/val_list.txt\n",
    "      # 数据预处理\n",
    "      transform_ops:\n",
    "        - DecodeImage:\n",
    "            to_rgb: True\n",
    "            channel_first: False\n",
    "        - ResizeImage:\n",
    "            resize_short: 256\n",
    "        - CropImage:\n",
    "            size: 224\n",
    "        - NormalizeImage:\n",
    "            scale: 1.0/255.0\n",
    "            mean: [0.485, 0.456, 0.406]\n",
    "            std: [0.229, 0.224, 0.225]\n",
    "            order: ''\n",
    "    sampler:\n",
    "      name: DistributedBatchSampler\n",
    "      batch_size: 128\n",
    "      drop_last: False\n",
    "      shuffle: True\n",
    "    loader:\n",
    "      num_workers: 0\n",
    "      use_shared_memory: True\n",
    "\n",
    "Infer:\n",
    "  infer_imgs: data/photography-1628649773318-753.jpg\n",
    "  batch_size: 10\n",
    "  transforms:\n",
    "    - DecodeImage:\n",
    "        to_rgb: True\n",
    "        channel_first: False\n",
    "    - ResizeImage:\n",
    "        resize_short: 256\n",
    "    - CropImage:\n",
    "        size: 224\n",
    "    - NormalizeImage:\n",
    "        scale: 1.0/255.0\n",
    "        mean: [0.485, 0.456, 0.406]\n",
    "        std: [0.229, 0.224, 0.225]\n",
    "        order: ''\n",
    "    - ToCHWImage:\n",
    "  PostProcess:\n",
    "    name: Topk\n",
    "    # 输出的可能性最高的前topk个\n",
    "    topk: 5\n",
    "    # 标签文件 需要自己新建文件\n",
    "    class_id_map_file: ./dataset/label_list.txt\n",
    "\n",
    "Metric:\n",
    "  Train:\n",
    "    - TopkAcc:\n",
    "        topk: [1, 5]\n",
    "  Eval:\n",
    "    - TopkAcc:\n",
    "        topk: [1, 5]\n",
    "```\n",
    "#### 3.1.2 标签文件\n",
    "这个是在预测时生成对照的依据，在上个文件有提到这个\n",
    "```\n",
    "# 标签文件 需要自己新建文件\n",
    "    class_id_map_file: dataset/label_list.txt\n",
    "```\n",
    "按照对应的进行编写：   \n",
    "\n",
    "![](https://ai-studio-static-online.cdn.bcebos.com/0e40a0afaa824ba9b70778aa7931a3baf2a421bcb81b4b0f83632da4e4ddc0ef)  \n",
    "\n",
    "如食品分类(要对照之前的txt的类别确认无误) \n",
    "```\n",
    "1 church\n",
    "2 lawn\n",
    "3 river\n",
    "4 ice\n",
    "5 desert\n",
    "```\n",
    "![](pictures/J1%EXE95`T]L]YDHW382DOI.png)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "![](https://ai-studio-static-online.cdn.bcebos.com/bd764090d0b547afb04dd7bce6a07afa1311241145d740c48452eab09eaab0ad)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 3.2 开始训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2021/08/11 11:30:37] root INFO: Already save model in ./output/ResNet50/latest\r"
     ]
    }
   ],
   "source": [
    "# 提示，运行过程中可能存在坏图的情况，但是不用担心，训练过程不受影响。\r\n",
    "# epochs=40\r\n",
    "!python3 tools/train.py \\\r\n",
    "    -c ./ppcls/configs/quick_start/new_user/ShuffleNetV2_x0_25.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 3.3 预测一张"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/aistudio/PaddleClas/ppcls/arch/backbone/model_zoo/vision_transformer.py:15: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working\n",
      "  from collections import Callable\n",
      "[2021/08/11 11:33:36] root INFO: \n",
      "===========================================================\n",
      "==        PaddleClas is powered by PaddlePaddle !        ==\n",
      "===========================================================\n",
      "==                                                       ==\n",
      "==   For more info please go to the following website.   ==\n",
      "==                                                       ==\n",
      "==       https://github.com/PaddlePaddle/PaddleClas      ==\n",
      "===========================================================\n",
      "\n",
      "[2021/08/11 11:33:36] root INFO: Arch : \n",
      "[2021/08/11 11:33:36] root INFO:     class_num : 6\n",
      "[2021/08/11 11:33:36] root INFO:     name : ResNet50\n",
      "[2021/08/11 11:33:36] root INFO: DataLoader : \n",
      "[2021/08/11 11:33:36] root INFO:     Eval : \n",
      "[2021/08/11 11:33:36] root INFO:         dataset : \n",
      "[2021/08/11 11:33:36] root INFO:             cls_label_path : ./dataset/scenes/val_list.txt\n",
      "[2021/08/11 11:33:36] root INFO:             image_root : ./dataset/\n",
      "[2021/08/11 11:33:36] root INFO:             name : ImageNetDataset\n",
      "[2021/08/11 11:33:36] root INFO:             transform_ops : \n",
      "[2021/08/11 11:33:36] root INFO:                 DecodeImage : \n",
      "[2021/08/11 11:33:36] root INFO:                     channel_first : False\n",
      "[2021/08/11 11:33:36] root INFO:                     to_rgb : True\n",
      "[2021/08/11 11:33:36] root INFO:                 ResizeImage : \n",
      "[2021/08/11 11:33:36] root INFO:                     resize_short : 256\n",
      "[2021/08/11 11:33:36] root INFO:                 CropImage : \n",
      "[2021/08/11 11:33:36] root INFO:                     size : 224\n",
      "[2021/08/11 11:33:36] root INFO:                 NormalizeImage : \n",
      "[2021/08/11 11:33:36] root INFO:                     mean : [0.485, 0.456, 0.406]\n",
      "[2021/08/11 11:33:36] root INFO:                     order : \n",
      "[2021/08/11 11:33:36] root INFO:                     scale : 1.0/255.0\n",
      "[2021/08/11 11:33:36] root INFO:                     std : [0.229, 0.224, 0.225]\n",
      "[2021/08/11 11:33:36] root INFO:         loader : \n",
      "[2021/08/11 11:33:36] root INFO:             num_workers : 0\n",
      "[2021/08/11 11:33:36] root INFO:             use_shared_memory : True\n",
      "[2021/08/11 11:33:36] root INFO:         sampler : \n",
      "[2021/08/11 11:33:36] root INFO:             batch_size : 128\n",
      "[2021/08/11 11:33:36] root INFO:             drop_last : False\n",
      "[2021/08/11 11:33:36] root INFO:             name : DistributedBatchSampler\n",
      "[2021/08/11 11:33:36] root INFO:             shuffle : True\n",
      "[2021/08/11 11:33:36] root INFO:     Train : \n",
      "[2021/08/11 11:33:36] root INFO:         dataset : \n",
      "[2021/08/11 11:33:36] root INFO:             cls_label_path : ./dataset/scenes/train_list.txt\n",
      "[2021/08/11 11:33:36] root INFO:             image_root : ./dataset/\n",
      "[2021/08/11 11:33:36] root INFO:             name : ImageNetDataset\n",
      "[2021/08/11 11:33:36] root INFO:             transform_ops : \n",
      "[2021/08/11 11:33:36] root INFO:                 DecodeImage : \n",
      "[2021/08/11 11:33:36] root INFO:                     channel_first : False\n",
      "[2021/08/11 11:33:36] root INFO:                     to_rgb : True\n",
      "[2021/08/11 11:33:36] root INFO:                 ResizeImage : \n",
      "[2021/08/11 11:33:36] root INFO:                     resize_short : 256\n",
      "[2021/08/11 11:33:36] root INFO:                 CropImage : \n",
      "[2021/08/11 11:33:36] root INFO:                     size : 224\n",
      "[2021/08/11 11:33:36] root INFO:                 RandFlipImage : \n",
      "[2021/08/11 11:33:36] root INFO:                     flip_code : 1\n",
      "[2021/08/11 11:33:36] root INFO:                 NormalizeImage : \n",
      "[2021/08/11 11:33:36] root INFO:                     mean : [0.485, 0.456, 0.406]\n",
      "[2021/08/11 11:33:36] root INFO:                     order : \n",
      "[2021/08/11 11:33:36] root INFO:                     scale : 1.0/255.0\n",
      "[2021/08/11 11:33:36] root INFO:                     std : [0.229, 0.224, 0.225]\n",
      "[2021/08/11 11:33:36] root INFO:         loader : \n",
      "[2021/08/11 11:33:36] root INFO:             num_workers : 0\n",
      "[2021/08/11 11:33:36] root INFO:             use_shared_memory : True\n",
      "[2021/08/11 11:33:36] root INFO:         sampler : \n",
      "[2021/08/11 11:33:36] root INFO:             batch_size : 128\n",
      "[2021/08/11 11:33:36] root INFO:             drop_last : False\n",
      "[2021/08/11 11:33:36] root INFO:             name : DistributedBatchSampler\n",
      "[2021/08/11 11:33:36] root INFO:             shuffle : True\n",
      "[2021/08/11 11:33:36] root INFO: Global : \n",
      "[2021/08/11 11:33:36] root INFO:     checkpoints : None\n",
      "[2021/08/11 11:33:36] root INFO:     device : gpu\n",
      "[2021/08/11 11:33:36] root INFO:     epochs : 40\n",
      "[2021/08/11 11:33:36] root INFO:     eval_during_train : True\n",
      "[2021/08/11 11:33:36] root INFO:     eval_interval : 1\n",
      "[2021/08/11 11:33:36] root INFO:     image_shape : [3, 224, 224]\n",
      "[2021/08/11 11:33:36] root INFO:     output_dir : ./output/\n",
      "[2021/08/11 11:33:36] root INFO:     pretrained_model : output/ResNet50/best_model\n",
      "[2021/08/11 11:33:36] root INFO:     print_batch_step : 1\n",
      "[2021/08/11 11:33:36] root INFO:     save_inference_dir : ./inference\n",
      "[2021/08/11 11:33:36] root INFO:     save_interval : 1\n",
      "[2021/08/11 11:33:36] root INFO:     to_static : False\n",
      "[2021/08/11 11:33:36] root INFO:     use_visualdl : True\n",
      "[2021/08/11 11:33:36] root INFO: Infer : \n",
      "[2021/08/11 11:33:36] root INFO:     PostProcess : \n",
      "[2021/08/11 11:33:36] root INFO:         class_id_map_file : ./dataset/label_list.txt\n",
      "[2021/08/11 11:33:36] root INFO:         name : Topk\n",
      "[2021/08/11 11:33:36] root INFO:         topk : 5\n",
      "[2021/08/11 11:33:36] root INFO:     batch_size : 10\n",
      "[2021/08/11 11:33:36] root INFO:     infer_imgs : dataset/photography-1628649773318-753.jpg\n",
      "[2021/08/11 11:33:36] root INFO:     transforms : \n",
      "[2021/08/11 11:33:36] root INFO:         DecodeImage : \n",
      "[2021/08/11 11:33:36] root INFO:             channel_first : False\n",
      "[2021/08/11 11:33:36] root INFO:             to_rgb : True\n",
      "[2021/08/11 11:33:36] root INFO:         ResizeImage : \n",
      "[2021/08/11 11:33:36] root INFO:             resize_short : 256\n",
      "[2021/08/11 11:33:36] root INFO:         CropImage : \n",
      "[2021/08/11 11:33:36] root INFO:             size : 224\n",
      "[2021/08/11 11:33:36] root INFO:         NormalizeImage : \n",
      "[2021/08/11 11:33:36] root INFO:             mean : [0.485, 0.456, 0.406]\n",
      "[2021/08/11 11:33:36] root INFO:             order : \n",
      "[2021/08/11 11:33:36] root INFO:             scale : 1.0/255.0\n",
      "[2021/08/11 11:33:36] root INFO:             std : [0.229, 0.224, 0.225]\n",
      "[2021/08/11 11:33:36] root INFO:         ToCHWImage : None\n",
      "[2021/08/11 11:33:36] root INFO: Loss : \n",
      "[2021/08/11 11:33:36] root INFO:     Eval : \n",
      "[2021/08/11 11:33:36] root INFO:         CELoss : \n",
      "[2021/08/11 11:33:36] root INFO:             weight : 1.0\n",
      "[2021/08/11 11:33:36] root INFO:     Train : \n",
      "[2021/08/11 11:33:36] root INFO:         CELoss : \n",
      "[2021/08/11 11:33:36] root INFO:             weight : 1.0\n",
      "[2021/08/11 11:33:36] root INFO: Metric : \n",
      "[2021/08/11 11:33:36] root INFO:     Eval : \n",
      "[2021/08/11 11:33:36] root INFO:         TopkAcc : \n",
      "[2021/08/11 11:33:36] root INFO:             topk : [1, 5]\n",
      "[2021/08/11 11:33:36] root INFO:     Train : \n",
      "[2021/08/11 11:33:36] root INFO:         TopkAcc : \n",
      "[2021/08/11 11:33:36] root INFO:             topk : [1, 5]\n",
      "[2021/08/11 11:33:36] root INFO: Optimizer : \n",
      "[2021/08/11 11:33:36] root INFO:     lr : \n",
      "[2021/08/11 11:33:36] root INFO:         decay_epochs : [30, 60, 90]\n",
      "[2021/08/11 11:33:36] root INFO:         learning_rate : 0.0125\n",
      "[2021/08/11 11:33:36] root INFO:         name : Piecewise\n",
      "[2021/08/11 11:33:36] root INFO:         values : [0.1, 0.01, 0.001, 0.0001]\n",
      "[2021/08/11 11:33:36] root INFO:     momentum : 0.9\n",
      "[2021/08/11 11:33:36] root INFO:     name : Momentum\n",
      "[2021/08/11 11:33:36] root INFO:     regularizer : \n",
      "[2021/08/11 11:33:36] root INFO:         coeff : 0.0005\n",
      "[2021/08/11 11:33:36] root INFO:         name : L2\n",
      "W0811 11:33:36.707304  4336 device_context.cc:404] Please NOTE: device: 0, GPU Compute Capability: 7.0, Driver API Version: 10.1, Runtime API Version: 10.1\n",
      "W0811 11:33:36.713097  4336 device_context.cc:422] device: 0, cuDNN Version: 7.6.\n",
      "[2021/08/11 11:33:42] root INFO: train with paddle 2.1.0 and device CUDAPlace(0)\n",
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/tensor/creation.py:125: DeprecationWarning: `np.object` is a deprecated alias for the builtin `object`. To silence this warning, use `object` by itself. Doing this will not modify any behavior and is safe. \n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  if data.dtype == np.object:\n",
      "[{'class_ids': [4, 5, 3, 1, 2], 'scores': [0.81915, 0.14509, 0.02771, 0.00714, 0.00091], 'file_name': 'dataset/photography-1628649773318-753.jpg', 'label_names': ['ice', 'desert', 'river', 'church', 'lawn']}]\n"
     ]
    }
   ],
   "source": [
    "# 更换为你训练的网络，需要预测的文件，上面训练所得到的的最优模型文件\r\n",
    "# 我这里是不严谨的，直接使用训练集的图片进行验证，大家可以去百度搜一些相关的图片传上来，进行预测\r\n",
    "!python3 tools/infer.py \\\r\n",
    "    -c ./ppcls/configs/quick_start/new_user/ShuffleNetV2_x0_25.yaml \\\r\n",
    "    -o Infer.infer_imgs=data/photography-1628649773318-753.jpg \\\r\n",
    "    -o Global.pretrained_model=output/ResNet50/best_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "运行完成，最后几行会得到结果如下形式：\n",
    "```\n",
    "[{'class_ids': [4, 5, 3, 1, 2],\n",
    "'scores': [0.81915, 0.14509, 0.02771, 0.00714, 0.00091], \n",
    "'file_name': 'data/photography-1628649773318-753.jpg', \n",
    "'label_names': ['ice', 'desert', 'river', 'church', 'lawn']}]\n",
    "```\n",
    "可以发现，预测结果不对，准确率很低，但整体的项目流程你已经掌握了！    \n",
    "训练轮数还有很大提升空间，自行变动参数直到预测正确为止~    \n",
    "\n",
    "<font size=\"3px\" color=\"red\">恭喜你学会了paddleclas图像分类！</font>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PaddlePaddle 2.1.2 (Python 3.5)",
   "language": "python",
   "name": "py35-paddle1.2.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
